{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>talk_id</th>\n",
       "      <th>view_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10474</td>\n",
       "      <td>07/27/2016 12:27:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10488</td>\n",
       "      <td>08/05/2016 12:34:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10506</td>\n",
       "      <td>08/07/2016 15:55:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10446</td>\n",
       "      <td>08/07/2016 15:58:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10506</td>\n",
       "      <td>08/07/2016 16:06:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  talk_id            view_time\n",
       "0        1    10474  07/27/2016 12:27:35\n",
       "1        1    10488  08/05/2016 12:34:01\n",
       "2        1    10506  08/07/2016 15:55:57\n",
       "3        1    10446  08/07/2016 15:58:09\n",
       "4        1    10506  08/07/2016 16:06:26"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task 2.1-User-based/Item-based Collaborative Filtering\n",
    "#By Liping Li and Saixiong Han\n",
    "\n",
    "#import train_user_view data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_user_view_df = pd.read_table('C:/Study/assignment8/train_user_view.txt')\n",
    "train_user_view_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>talk_id</th>\n",
       "      <th>view_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10446</td>\n",
       "      <td>08/07/2016 15:58:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>10446</td>\n",
       "      <td>08/08/2016 18:18:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>10446</td>\n",
       "      <td>08/09/2016 10:38:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>10446</td>\n",
       "      <td>08/09/2016 10:39:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>10446</td>\n",
       "      <td>08/09/2016 16:33:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  talk_id            view_time\n",
       "3        1    10446  08/07/2016 15:58:09\n",
       "5        1    10446  08/08/2016 18:18:46\n",
       "6        1    10446  08/09/2016 10:38:38\n",
       "7        1    10446  08/09/2016 10:39:33\n",
       "8        1    10446  08/09/2016 16:33:56"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = train_user_view_df.sort_values(['user_id','talk_id','view_time'],ascending=[True,True,True])\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 users\n",
      "165 talks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 10446.,  10446.,  10446., ...,      0.,      0.,      0.],\n",
       "       [ 10636.,  10636.,  10636., ...,  10634.,  10636.,  10636.],\n",
       "       [ 10516.,  10517.,  10532., ...,      0.,      0.,      0.],\n",
       "       ..., \n",
       "       [ 10634.,      0.,      0., ...,      0.,      0.,      0.],\n",
       "       [ 10666.,  10666.,  10666., ...,      0.,      0.,      0.],\n",
       "       [ 10583.,  10591.,  10702., ...,      0.,      0.,      0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the train_user_view.txt into a user-talk matrix.\n",
    "n_users = train_user_view_df.user_id.unique().shape[0]\n",
    "n_talks = train_user_view_df.talk_id.unique().shape[0]\n",
    "print str(n_users) + ' users'\n",
    "print str(n_talks) + ' talks'\n",
    "ctr =0\n",
    "ctr2 = 0\n",
    "temp = 0\n",
    "comments = np.zeros((n_users, n_talks))\n",
    "for row in new_df.itertuples():\n",
    "    if (row[1]-1)!=temp:\n",
    "        ctr = 0\n",
    "        ctr2 = ctr2+1\n",
    "    comments[ctr2, ctr] = row[2]\n",
    "    if (ctr+1)<n_talks:\n",
    "        ctr += 1\n",
    "    else: \n",
    "        ctr = 0\n",
    "    temp = row[1]-1\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 20.44%\n"
     ]
    }
   ],
   "source": [
    "sparsity = float(len(comments.nonzero()[0]))\n",
    "sparsity /= (comments.shape[0] * comments.shape[1])\n",
    "sparsity *= 100\n",
    "print 'Sparsity: {:4.2f}%'.format(sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split the data into 80/10/10 trainning/validation/test data\n",
    "\n",
    "def train_rest_split(comments):\n",
    "    rest = np.zeros(comments.shape)\n",
    "    train = comments.copy()\n",
    "    for user in xrange(comments.shape[0]):\n",
    "        rest_comments = np.random.choice(comments[user, :].nonzero()[0], \n",
    "                                        size=20, \n",
    "                                        replace=True)\n",
    "        train[user, rest_comments] = 0.\n",
    "        rest[user, rest_comments] = comments[user, rest_comments]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * rest) == 0)) \n",
    "    return train, rest\n",
    "\n",
    "train, rest = train_rest_split(comments)\n",
    "\n",
    "def valida_test_split(rest):\n",
    "    test = np.zeros(rest.shape)\n",
    "    valida = rest.copy()\n",
    "    for user in xrange(rest.shape[0]):\n",
    "        test_comments = np.random.choice(rest[user, :].nonzero()[0], \n",
    "                                        size=50, \n",
    "                                        replace=True)\n",
    "        valida[user, test_comments] = 0.\n",
    "        test[user, test_comments] = rest[user, test_comments]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * rest) == 0)) \n",
    "    return valida, test\n",
    "\n",
    "valida, test = valida_test_split(rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Item-based Collaborative Filtering\n",
    "#item-similarity matrix will measure the similarity between any two pairs of items.\n",
    "def slow_similarity(comments, kind='user'):\n",
    "    if kind == 'user':\n",
    "        axmax = 0\n",
    "        axmin = 1\n",
    "    elif kind == 'talk':\n",
    "        axmax = 1\n",
    "        axmin = 0\n",
    "    sim = np.zeros((comments.shape[axmax], comments.shape[axmax]))\n",
    "    for u in xrange(comments.shape[axmax]):\n",
    "        for uprime in xrange(comments.shape[axmax]):\n",
    "            rui_sqrd = 0.\n",
    "            ruprimei_sqrd = 0.\n",
    "            for i in xrange(comments.shape[axmin]):\n",
    "                sim[u, uprime] = comments[u, i] * comments[uprime, i]\n",
    "                rui_sqrd += comments[u, i] ** 2\n",
    "                ruprimei_sqrd += comments[uprime, i] ** 2\n",
    "            sim[u, uprime] /= rui_sqrd * ruprimei_sqrd\n",
    "    return sim\n",
    "\n",
    "def fast_similarity(comments, kind='user', epsilon=1e-9):\n",
    "    # epsilon -> small number for handling dived-by-zero errors\n",
    "    if kind == 'user':\n",
    "        sim = comments.dot(comments.T) + epsilon\n",
    "    elif kind == 'talk':\n",
    "        sim = comments.T.dot(comments) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / norms / norms.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 722.61 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 38.4 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit fast_similarity(train, kind='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel\\__main__.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 286 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit slow_similarity(train, kind='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.7078604   0.69358752  0.92858451]\n",
      " [ 0.7078604   1.          0.54638255  0.70809208]\n",
      " [ 0.69358752  0.54638255  1.          0.69376149]\n",
      " [ 0.92858451  0.70809208  0.69376149  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "user_similarity_f = fast_similarity(train, kind='user')\n",
    "talk_similarity_f = fast_similarity(train, kind='talk')\n",
    "print talk_similarity_f[:4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#user_based collaborating filtering\n",
    "\n",
    "def predict_slow_simple(comments, similarity, kind='user'):\n",
    "    pred = np.zeros(comments.shape)\n",
    "    if kind == 'user':\n",
    "        for i in xrange(comments.shape[0]):\n",
    "            for j in xrange(comments.shape[1]):\n",
    "                pred[i, j] = similarity[i, :].dot(comments[:, j])\\\n",
    "                             /np.sum(np.abs(similarity[i, :]))\n",
    "        return pred\n",
    "    elif kind == 'talk':\n",
    "        for i in xrange(comments.shape[0]):\n",
    "            for j in xrange(comments.shape[1]):\n",
    "                pred[i, j] = similarity[j, :].dot(comments[i, :].T)\\\n",
    "                             /np.sum(np.abs(similarity[j, :]))\n",
    "\n",
    "        return pred\n",
    "\n",
    "def predict_fast_simple(comments, similarity, kind='user'):\n",
    "    if kind == 'user':\n",
    "        return similarity.dot(comments) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif kind == 'talk':\n",
    "        return comments.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 34 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit predict_slow_simple(train, user_similarity_f, kind='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 6.48 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 42.4 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit predict_fast_simple(train, user_similarity_f, kind='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 35957120.4698\n",
      "Talk-based CF MSE: 37266139.3729\n"
     ]
    }
   ],
   "source": [
    "#get result from training dataset and validation dataset\n",
    "\n",
    "talk_prediction = predict_fast_simple(train, talk_similarity_f, kind='talk')\n",
    "user_prediction = predict_fast_simple(train, user_similarity_f, kind='user')\n",
    "\n",
    "print 'User-based CF MSE: ' + str(get_mse(user_prediction, valida))\n",
    "print 'Talk-based CF MSE: ' + str(get_mse(talk_prediction, valida))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 50002156.9582\n",
      "Talk-based CF MSE: 71853515.2318\n"
     ]
    }
   ],
   "source": [
    "#get result from training dataset and test dataset\n",
    "\n",
    "talk_prediction = predict_fast_simple(train, talk_similarity_f, kind='talk')\n",
    "user_prediction = predict_fast_simple(train, user_similarity_f, kind='user')\n",
    "\n",
    "print 'User-based CF MSE: ' + str(get_mse(user_prediction, test))\n",
    "print 'Talk-based CF MSE: ' + str(get_mse(talk_prediction, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Task 2.2-Matrix Factorization\n",
    "#define the matrix_factorization\n",
    "import numpy\n",
    "\n",
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in xrange(steps):\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - numpy.dot(P[i,:],Q[:,j])\n",
    "                    for k in xrange(K):\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = numpy.dot(P,Q)\n",
    "        e = 0\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - numpy.dot(P[i,:],Q[:,j]), 2)\n",
    "                    for k in xrange(K):\n",
    "                        e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel\\__main__.py:14: RuntimeWarning: overflow encountered in double_scalars\n",
      "c:\\python27\\lib\\site-packages\\ipykernel\\__main__.py:13: RuntimeWarning: overflow encountered in double_scalars\n",
      "c:\\python27\\lib\\site-packages\\ipykernel\\__main__.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\python27\\lib\\site-packages\\ipykernel\\__main__.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\python27\\lib\\site-packages\\ipykernel\\__main__.py:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\python27\\lib\\site-packages\\ipykernel\\__main__.py:22: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\python27\\lib\\site-packages\\ipykernel\\__main__.py:22: RuntimeWarning: overflow encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "#Get the matrix factorization of training data\n",
    "\n",
    "N = len(train)\n",
    "M = len(train[0])\n",
    "K = 2\n",
    "\n",
    "P = numpy.random.rand(N,K)\n",
    "Q = numpy.random.rand(M,K)\n",
    "\n",
    "nP, nQ = matrix_factorization(train, P, Q, K)\n",
    "nR = numpy.dot(nP, nQ.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[        nan         nan         nan ...,         nan         nan\n",
      "          nan]\n",
      " [        nan         nan         nan ...,         nan         nan\n",
      "          nan]\n",
      " [        nan         nan         nan ...,  0.61453516         nan\n",
      "          nan]\n",
      " ..., \n",
      " [        nan         nan         nan ...,  0.70864507         nan\n",
      "          nan]\n",
      " [        nan         nan         nan ...,         nan         nan\n",
      "          nan]\n",
      " [        nan         nan         nan ...,  1.00379919         nan\n",
      "          nan]]\n"
     ]
    }
   ],
   "source": [
    "print nR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta=1, eta=0.1, init='random', l1_ratio=0.0, max_iter=200,\n",
       "  n_components=2, nls_max_iter=2000, random_state=0, shuffle=False,\n",
       "  solver='cd', sparseness=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since I don't know how to use the example to get the accuracy of training data and test data\n",
    "#I used a sklearn package called Non-Negative Matrix Factorization (NMF)\n",
    "#This way I can get the accuracy at least\n",
    "X = np.array(train)\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=2, init='random', random_state=0)\n",
    "model.fit(X) \n",
    "NMF(alpha=0.0, beta=1, eta=0.1, init='random', l1_ratio=0.0, max_iter=200,\n",
    "  n_components=2, nls_max_iter=2000, random_state=0, shuffle=False,\n",
    "  solver='cd', sparseness=None, tol=0.0001, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 38.33969294,  34.69165073,  42.87668592,  38.55081422,\n",
       "         32.04162031,  42.77534471,  34.32147887,  39.38313969,\n",
       "         33.93625288,  28.18142585,  29.46942033,  41.6706407 ,\n",
       "         41.01902362,  43.62743459,  12.85758172,  33.24884706,\n",
       "         35.77679586,  35.0697303 ,  34.43292329,  40.58168399,\n",
       "         37.81703833,  37.90633121,  32.78898653,  38.16885223,\n",
       "         26.4940717 ,  40.87498102,  38.17015081,  14.00206635,\n",
       "         45.87471204,  33.93093601,  32.47709909,  31.93019302,\n",
       "         44.28623686,  31.45915653,  42.42254232,  40.33598192,\n",
       "         20.14837335,  31.42075325,  44.07116725,  30.32700458,\n",
       "         29.45755887,  33.50569824,  44.67754267,  44.69511153,\n",
       "         32.4775929 ,  31.88445041,  46.56806066,  46.53374968,\n",
       "         48.72819182,  21.53290787,  35.91448879,  44.74938261,\n",
       "         46.58876758,  46.91414814,  46.91892995,  48.78792413,\n",
       "         48.80929927,  44.79691941,  46.66710898,  30.74193021,\n",
       "         46.67381605,  33.82348669,  10.47031929,  37.1293172 ,\n",
       "         29.87900434,  36.05186206,  48.94711621,  48.94711621,\n",
       "         39.30514396,  48.49737652,  20.6896789 ,  48.23223391,\n",
       "         39.21900066,  48.6807199 ,  48.6807199 ,  48.6860529 ,\n",
       "         37.96702503,  42.51261889,  39.0566636 ,  38.53166502,\n",
       "         39.229589  ,  37.66908664,  48.28534248,  38.90241206,\n",
       "         28.1953361 ,  48.29487416,  38.56098634,  48.32817331,\n",
       "         36.09402429,  37.72666002,  15.71077578,  48.36093184,\n",
       "         41.42839327,  48.37647227,  48.38383945,  29.62080931,\n",
       "         48.38916054,  32.03952473,  48.40901155,  48.41397088,\n",
       "         38.99943203,  48.41877321,  48.42137346,  48.42478621,\n",
       "         41.48967953,  48.43461858,  48.43671972,  48.44152932,\n",
       "         48.46009257,  41.50248461,  31.73145466,  31.75086342,\n",
       "         29.69900827,  41.5472634 ,  32.11070335,  31.1433225 ,\n",
       "         19.97722048,  41.72024888,  31.92466092,  41.74327132,\n",
       "         41.74998379,  31.26810118,  41.7628771 ,  41.76497823,\n",
       "         41.76585827,  41.77710689,  32.18843637,  22.35693341,\n",
       "         22.36492889,  32.20215509,  32.2122517 ,  32.2122517 ,\n",
       "         21.70263758,  32.21716365,  32.22176814,  22.38664993,\n",
       "         22.38664993,  22.38664993,  11.87212385,  11.87212385,\n",
       "         11.87212385,  11.87324259,  11.87548008,  11.87659883,\n",
       "         11.87771757,   0.        ,  11.87995506,  11.87995506,\n",
       "         11.87995506,  11.87995506,  11.88107381,  11.88107381,\n",
       "         11.88107381,  11.88219255,  11.88219255,  11.88219255,\n",
       "          0.        ,  11.88666753,   0.        ,  11.88778628,\n",
       "         11.88890502,  11.89673624,  11.89673624,  11.89897373,   0.        ],\n",
       "       [ 83.17120333,  28.81488037,  51.2920935 ,  82.17588878,\n",
       "         62.91054928,  53.46661672,  48.81007808,  76.38688665,\n",
       "         47.23399168,  83.09930177,  62.76946184,  60.80244128,\n",
       "         65.81856523,  47.45828294,  45.96419245,  51.77123897,\n",
       "         39.1975955 ,  42.43934055,  64.15361832,  69.18066583,\n",
       "         73.13737242,  39.43287968,  59.24525304,  86.42151292,\n",
       "         55.29509824,  67.44217817,  86.48061503,  59.30405447,\n",
       "         31.40573569,  43.57636397,  61.61453723,  41.54659386,\n",
       "         43.20069973,  68.87076655,  56.57967591,  56.2312432 ,\n",
       "         40.79634225,  61.61183475,  45.15189716,  42.79737183,\n",
       "         34.42643772,  51.78920208,  41.64797184,  41.64517768,\n",
       "         54.46882174,  32.09928718,  28.08552873,  12.6693853 ,\n",
       "         12.44689656,  47.56430687,  30.19507429,  41.73009605,\n",
       "         12.6971621 ,  26.06404911,  26.0771055 ,  12.46754434,\n",
       "         12.46167697,  41.77135415,  28.15161322,  10.39556125,\n",
       "         28.17580709,  18.60887644,  11.87661395,  27.56197149,\n",
       "         25.19630022,  30.27468516,  12.45935058,  12.45935058,\n",
       "         11.87158237,   0.        ,  11.89826235,   0.        ,\n",
       "         13.20069807,  12.54809819,  12.54809819,  12.54772823,\n",
       "         14.64491844,   7.51517463,  11.98059521,   0.        ,\n",
       "         13.22856652,   1.23897555,   0.        ,   0.        ,\n",
       "          1.8978145 ,   0.        ,   0.        ,   0.        ,\n",
       "          2.9252059 ,   1.25183948,   4.4206385 ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,   0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the matrix factorization\n",
    "model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155369.56209961325"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The accuracy of the training data and test data\n",
    "model.reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta=1, eta=0.1, init='random', l1_ratio=0.0, max_iter=200,\n",
       "  n_components=2, nls_max_iter=2000, random_state=0, shuffle=False,\n",
       "  solver='cd', sparseness=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(valida)\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=2, init='random', random_state=0)\n",
    "model.fit(X) \n",
    "NMF(alpha=0.0, beta=1, eta=0.1, init='random', l1_ratio=0.0, max_iter=200,\n",
    "  n_components=2, nls_max_iter=2000, random_state=0, shuffle=False,\n",
    "  solver='cd', sparseness=None, tol=0.0001, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31256.901825180175"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The accuarcy of validation data\n",
    "model.reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
